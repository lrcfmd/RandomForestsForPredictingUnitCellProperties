{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stock-lounge",
   "metadata": {},
   "source": [
    "## Supporting code for 'Chemically Controllable Magnetic Transition Temperature and Magneto-Elastic Coupling in MnZnSb Compounds'\n",
    "\n",
    "Here we give an example for one dataset in which we load in the data, make predictions and measure metrics. Then we look at random pairings as discussed in the supporting material for this paper and evaluate these both with metrics and comparing these to metrics found using Shannon Radius as a naive proxy indicator.\n",
    "\n",
    "Finally We perform leave one cluster out cross validation (LOCO-CV) for these measurements (Meredig et al. 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fancy-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Natives\n",
    "import json\n",
    "import os\n",
    "#Libraries\n",
    "import pandas as pd\n",
    "from pymatgen.core.periodic_table import Element\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-pantyhose",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "Defining these first so that they can be itterated over later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "least-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'r^2': r2_score,\n",
    "    'mean relative error': mean_absolute_percentage_error\n",
    "}\n",
    "#For paired data we can include information about the 'parent compound' (see SI for more info), so I will be using metric(parent, y_true, y_pred) for these\n",
    "paired_metrics = {\n",
    "    'r^2': lambda parent, true, pred: r2_score(true, pred),\n",
    "    'mean relative error': lambda parent, true, pred: mean_absolute_percentage_error(true,pred),\n",
    "    'r^2_{comp}':lambda parent, true, pred: r2_score(true-parent, pred-parent),\n",
    "    'accuracy':  lambda parent, true, pred: sum((parent>true) == (parent>pred))/len(pred) #Where multipe columns are targets this may need to be rewritten\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-rocket",
   "metadata": {},
   "source": [
    "### Defining variables where data should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "thirty-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'PbFCl' # Change this to see results with other datasets, note that larger datasets take more time to process\n",
    "data_folder = 'Data'\n",
    "shannon_radii_file = 'Data/shannon.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "painful-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = os.path.join(data_folder, dataset, f'{dataset}.csv') # Data\n",
    "train_test_split_file = os.path.join(data_folder, dataset, f'{dataset}_80_20_split.csv') # random split 80%:20% train vs test data\n",
    "LOCO_CV_split_file = os.path.join(data_folder, dataset, f'{dataset}_LOCO_CV_split.json') # clusterings for LOCO-CV for values of k 2-10\n",
    "\n",
    "paired_train_test_split_file = os.path.join(data_folder, dataset, f'paired_{dataset}_80_20_split.csv') # Randomly paired data in 80%:20% split\n",
    "paired_CV_split_file = os.path.join(data_folder, dataset, f'paired_{dataset}_LOCO_CV_split.json') # Randomly paired data clustered for LOCO-CV values of k 2-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ignored-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lattice_parameter_columns = ['a','b','c','c_over_a','alpha','beta','gamma','volume']\n",
    "target_column = 'c_over_a' # If you want to predict other lattice parameters you can change this to something from the list above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "original-colonial",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-windsor",
   "metadata": {},
   "source": [
    "### Split into train-test and regress to find target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "helpful-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data.drop(lattice_parameter_columns,axis='columns')\n",
    "Y = all_data[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "sacred-eclipse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2: 0.7922038920220958\n",
      "\n",
      "mean relative error: 0.02272347016589212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "is_train = pd.read_csv(train_test_split_file,header=None)[0] #[0] converts to Series type from DataFrame\n",
    "train_X = X[is_train]\n",
    "train_Y = Y[is_train]\n",
    "\n",
    "test_X = X[~is_train]\n",
    "test_Y = Y[~is_train]\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(train_X, train_Y)\n",
    "predictions = rf.predict(test_X)\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f'{metric}: {metrics[metric](test_Y, predictions)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-eugene",
   "metadata": {},
   "source": [
    "## Now paired predictions\n",
    "\n",
    "These can be used for substitutional studies where a parent material is known and we want to predict what could be substituted in to make a change to a child's lattice parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "nasty-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pair compounds together\n",
    "pairs = pd.read_csv(paired_train_test_split_file)\n",
    "parents = all_data.iloc[pairs['p1']] #Data for parent compound\n",
    "children = all_data.iloc[pairs['p2']] #Data for child compound\n",
    "parents = parents.rename(lambda x:f'{x}_parent', axis='columns')\n",
    "parents.index = pairs.index\n",
    "children.index = pairs.index\n",
    "paired_data = parents.merge(children,right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "anticipated-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = paired_data.drop(lattice_parameter_columns,axis='columns')\n",
    "Y = paired_data[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "subjective-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes quite a while\n",
    "is_train = pairs['is_train']\n",
    "train_X = X[is_train]\n",
    "train_Y = Y[is_train]\n",
    "\n",
    "test_X = X[~is_train]\n",
    "test_Y = Y[~is_train]\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(train_X, train_Y)\n",
    "predictions = rf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "controlled-carbon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2: 0.7518100168903582\n",
      "\n",
      "mean relative error: 0.02231132835006816\n",
      "\n",
      "r^2_{comp}: 0.8764821944524108\n",
      "\n",
      "accuracy: 0.9475331449684851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for metric in paired_metrics:\n",
    "    print(f'{metric}: {paired_metrics[metric](test_X[f\"{target_column}_parent\"], test_Y, predictions)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-rendering",
   "metadata": {},
   "source": [
    "## Using shannon radius as benchmark\n",
    "-1 is used to mean shannon radius was not found, so we take the weighted mean of shannon radii but ignore anything negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ahead-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "shannons = pd.read_csv(shannon_radii_file).iloc[0] #.iloc[0] converts to a series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-foster",
   "metadata": {},
   "source": [
    "#### Weighted average shannon Radius of parent compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "musical-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_formulae = parents.drop([f'{x}_parent' for x in lattice_parameter_columns], axis='columns')\n",
    "parent_weighted_shannon_radius = parent_formulae*shannons.rename(lambda x: f'{x}_parent')\n",
    "\n",
    "#find proportion with radius found\n",
    "proportion_with_no_radius_found = (parent_weighted_shannon_radius*(parent_weighted_shannon_radius<0)).abs()\n",
    "proportion_with_radius = 1-proportion_with_no_radius_found.sum(axis='columns')\n",
    "#Find the weighted mean, and set anything negative to 0, scale the value where some radii were missing\n",
    "parent_weighted_shannon_radius = parent_weighted_shannon_radius.clip(lower=0).sum(axis='columns')/proportion_with_radius"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-intelligence",
   "metadata": {},
   "source": [
    "#### Weighted average shannon radius of child compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "weighted-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_formulae = children.drop(lattice_parameter_columns, axis='columns')\n",
    "child_weighted_shannon_radius = child_formulae*shannons\n",
    "\n",
    "#find proportion with radius found\n",
    "proportion_with_no_radius_found = (child_weighted_shannon_radius*(child_weighted_shannon_radius<0)).abs()\n",
    "proportion_with_radius = 1-proportion_with_no_radius_found.sum(axis='columns')\n",
    "#Find the weighted mean, and set anything negative to 0, scale the value where some radii were missing\n",
    "child_weighted_shannon_radius = child_weighted_shannon_radius.clip(lower=0).sum(axis='columns')/proportion_with_radius"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-angle",
   "metadata": {},
   "source": [
    "#### Measure performance of this proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "statutory-range",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2 -3.0958093430887645 \n",
      "\n",
      "r^2_{comp} -0.061028570161959284 \n",
      "\n",
      "accuracy 0.5674393118827652\n"
     ]
    }
   ],
   "source": [
    "print('r^2',r2_score(child_weighted_shannon_radius, children[target_column]),'\\n')\n",
    "\n",
    "difference_in_radius = parent_weighted_shannon_radius-child_weighted_shannon_radius\n",
    "difference_in_lattice_param =  parents[f'{target_column}_parent'] - children[target_column]\n",
    "print('r^2_{comp}', r2_score(difference_in_radius, difference_in_lattice_param),'\\n')\n",
    "direction_of_radius_change = difference_in_radius>0\n",
    "direction_of_lattice_change = difference_in_lattice_param>0\n",
    "print('accuracy', sum(direction_of_radius_change==direction_of_lattice_change)/len(difference_in_radius))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-prior",
   "metadata": {},
   "source": [
    "## Measuring extrapolatory power of these algorithms using leave one cluster out cross validation\n",
    "\n",
    "#### First for normal predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "invalid-journey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2: -2.0577957719514477\n",
      "\n",
      "mean relative error: 0.08556325415449972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(LOCO_CV_split_file) as f:\n",
    "    LOCO_CV_splits = json.load(f)\n",
    "    \n",
    "results = {metric:[] for metric in metrics} # Store the average results for all clusterings\n",
    "\n",
    "X = all_data.drop(lattice_parameter_columns,axis='columns')\n",
    "Y = all_data[target_column]\n",
    "\n",
    "for k in LOCO_CV_splits:\n",
    "    clustering_results = {metric:[] for metric in metrics} #Store the result for this value of k\n",
    "    asigned_clusters = pd.Series(LOCO_CV_splits[k])\n",
    "    \n",
    "    k = int(k)\n",
    "    print(f'Processing for k = {k}\\r',end='')\n",
    "    \n",
    "    for i in range(k):\n",
    "        is_train = asigned_clusters != i\n",
    "        train_X = X[is_train]\n",
    "        train_Y = Y[is_train]\n",
    "\n",
    "        test_X = X[~is_train]\n",
    "        test_Y = Y[~is_train]\n",
    "\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(train_X, train_Y)\n",
    "        predictions = rf.predict(test_X)\n",
    "        \n",
    "        [clustering_results[metric].append(metrics[metric](test_Y, predictions)) for metric in metrics]\n",
    "    #Now average accross each cluster for this value of k\n",
    "    [results[metric].append(sum(clustering_results[metric])/k) for metric in metrics]\n",
    "\n",
    "#Average accross all values of k and print out:\n",
    "for metric in metrics:\n",
    "    print(f'{metric}: {sum(results[metric])/len(results[metric])}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-bicycle",
   "metadata": {},
   "source": [
    "#### For paired predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "hired-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paired_CV_split_file) as f:\n",
    "    LOCO_CV_splits = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-fifth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for k = 3\r"
     ]
    }
   ],
   "source": [
    "# This takes several hours to run    \n",
    "results = {metric:[] for metric in paired_metrics} # Store the average results for all clusterings\n",
    "\n",
    "\n",
    "\n",
    "for k in LOCO_CV_splits:\n",
    "    clustering_results = {metric:[] for metric in paired_metrics} #Store the result for this value of k\n",
    "    pairings = pd.DataFrame(LOCO_CV_splits[k], columns=['p1','p2', 'cluster'])\n",
    "    \n",
    "    #Find data for each pair\n",
    "    parents = all_data.iloc[pairings['p1']] #Data for parent compound\n",
    "    children = all_data.iloc[pairings['p2']] #Data for child compound\n",
    "    parents = parents.rename(lambda x:f'{x}_parent', axis='columns')\n",
    "    parents.index = pairings.index\n",
    "    children.index = pairings.index\n",
    "    paired_data = parents.merge(children,right_index=True, left_index=True)\n",
    "    \n",
    "    X = paired_data.drop(lattice_parameter_columns,axis='columns')\n",
    "    Y = paired_data[target_column]\n",
    "    \n",
    "    k = int(k)\n",
    "    \n",
    "    print(f'Processing for k = {k}\\r',end='')\n",
    "    \n",
    "    for i in range(k):\n",
    "        is_train = pairings['cluster'] != i\n",
    "        train_X = X[is_train]\n",
    "        train_Y = Y[is_train]\n",
    "\n",
    "        test_X = X[~is_train]\n",
    "        test_Y = Y[~is_train]\n",
    "\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(train_X, train_Y)\n",
    "        predictions = rf.predict(test_X)\n",
    "        \n",
    "        [clustering_results[metric].append(paired_metrics[metric](test_X[f'{target_column}_parent'], test_Y, predictions)) for metric in paired_metrics]\n",
    "    #Now average accross each cluster for this value of k\n",
    "    [results[metric].append(sum(clustering_results[metric])/k) for metric in paired_metrics]\n",
    "\n",
    "#Average accross all values of k and print out:\n",
    "for metric in paired_metrics:\n",
    "    print(f'{metric}: {sum(results[metric])/len(results[metric])}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-comparative",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
